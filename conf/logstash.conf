# Logstash configs for use with Toil and LSF

input {
    # Filebeat input
    beats {
        # port to listen for Filebeat messages
        port => "5044"
    }

    # input from stdin; $ cat lsf.log | logstash ..
    stdin {
        # handling for multiline entries e.g. from tracebacks and CWL warnings
        # NOTE: multiline does not work with beats input
        codec => multiline {
            # https://sematext.com/blog/handling-stack-traces-with-logstash/
            # lines starting with whitespace get appened to previous entry
            # https://www.elastic.co/guide/en/logstash/current/plugins-codecs-multiline.html
            pattern => "^\s"
            what => "previous"

            # TODO: figure out how to also capture the LSF log information at the tail of the file
        }
    }

}

filter {
    grok {
        # https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/ecs-v1/grok-patterns
        # https://github.com/kkos/oniguruma/blob/master/doc/RE
        # https://grokdebug.herokuapp.com/
        match => {
            "message" => [
            # # Normal log messages;
            # jx22 2021-05-17 17:14:05,824 MainThread INFO cwltool: Resolved '/work/ci/beagle/work/09f7d864-f23d-4392-922e-849d4ae21e95/pluto-cwl/cwl/workflow_with_facets.cwl' to 'file:///work/ci/beagle/work/09f7d864-f23d-4392-922e-849d4ae21e95/pluto-cwl/cwl/workflow_with_facets.cwl'
            "%{WORD:hostname} %{TIMESTAMP_ISO8601:timestamp} %{WORD:thread} %{LOGLEVEL:loglevel} (?<app>[\S]*): %{GREEDYDATA:message}",

            # # error messages;
            # ../../work/ci/beagle/work/09f7d864-f23d-4392-922e-849d4ae21e95/pluto-cwl/cwl/put_in_dir.cwl:32:1: JSHINT:                                                     ^
            "(?<path>[\S]*.cwl):%{INT:line}:%{INT:col}: %{GREEDYDATA:message}"
            ]
        }
    }
}


output {
    # push a copy of each event to ElasticSearch
    elasticsearch {
        # https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html
        hosts => ["${ES_URL}"] # get this from exported environment variables # http://elasticsearch.com:1234
        index => "${ES_INDEX}" # name of es index to use; should auto-create by default
        document_id => "%{id}" # NOTE: this needs to come from filter or be pre-created
        # doc_as_upsert => true
        # user => “es_user”
        # password => “es_password”
    }

    # pretty-print a copy of each event + metadata to console stdout
    # https://www.elastic.co/guide/en/logstash/current/plugins-outputs-stdout.html
    stdout { codec => rubydebug }
    # stdout { codec => rubydebug { metadata => true } }
    # stdout { codec => json }
}



# TODO: need handling for these log messages;
# {
#     "@timestamp" => 2021-05-24T18:55:26.524Z,
#        "message" => "5-17 17:14:46,573 MainThread INFO toil.worker: ---TOIL WORKER OUTPUT LOG---",
#           "host" => "silo",
#           "tags" => [
#         [0] "_grokparsefailure"
#     ],
#       "@version" => "1"
# }
# {
#     "@timestamp" => 2021-05-24T18:55:26.559Z,
#        "message" => "jx22 2021-05-17 17:16:06,125 Ma",
#           "host" => "silo",
#           "tags" => [
#         [0] "_grokparsefailure"
#     ],
#       "@version" => "1"
# }
# {
#     "@timestamp" => 2021-05-24T18:55:26.543Z,
#        "message" => "ga/cleanup/file-yqbjbfq7/stream with less than 10% of disk space remaining.",
#           "host" => "silo",
#           "tags" => [
#         [0] "_grokparsefailure"
#     ],
#       "@version" => "1"
# }
# {
#     "@timestamp" => 2021-05-24T18:55:26.559Z,
#        "message" => "inThread INFO toil: Running Toil version 3.21.0-80000ee6bd187322bcada6bbd88f14de193f9504.",
#           "host" => "silo",
#           "tags" => [
#         [0] "_grokparsefailure"
#     ],
#       "@version" => "1"
# }
